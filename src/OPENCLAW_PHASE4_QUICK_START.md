# ðŸš€ OpenClaw Phase 4: Quick Start Guide

**Get up and running with the 8 AI optimization systems in 5 minutes**

---

## ðŸ“‹ PREREQUISITES

All systems are **already deployed** and ready to use. No setup required!

âœ… Backend systems running on Supabase Edge Functions  
âœ… All routes configured and active  
âœ… Auto-initialization on first request

---

## ðŸŽ¯ QUICK WINS (Start Here)

### **1. View AI Observatory Dashboard (1 minute)**

**What:** See real-time monitoring of all AI systems

**How:**
1. Navigate to `/admin/ai-observatory` (or use the AIObservatoryDashboard component)
2. View key metrics: requests, costs, latency, cache hit rate
3. Check for active alerts
4. Review cost projections

**Expected Result:** Full visibility into AI performance

---

### **2. Enable Semantic Caching (Automatic)**

**What:** 70% cost reduction with zero code changes

**How:** Already enabled! The cache automatically:
- Intercepts similar queries
- Returns cached responses in <100ms
- Updates statistics in real-time

**Verify:**
```typescript
// Check cache stats
const response = await fetch(
  `https://kwhnrlzibgfedtxpkbgb.supabase.co/functions/v1/make-server-57781ad9/ai/cache/stats`,
  { headers: { 'Authorization': `Bearer ${publicAnonKey}` } }
);
const { stats } = await response.json();
console.log(`Cache hit rate: ${stats.hitRate}%`);
```

**Expected Result:** 60-80% hit rate after initial warm-up

---

### **3. Smart Model Routing (Automatic)**

**What:** Automatically use DeepSeek (10x cheaper) for structured tasks

**How:** Already enabled! The router automatically:
- Analyzes each query
- Routes to optimal model
- Tracks cost savings

**Verify:**
```typescript
// Check router stats
const response = await fetch(
  `https://kwhnrlzibgfedtxpkbgb.supabase.co/functions/v1/make-server-57781ad9/ai/router/stats`,
  { headers: { 'Authorization': `Bearer ${publicAnonKey}` } }
);
const { stats } = await response.json();
console.log(`Using DeepSeek: ${stats.deepseekPercentage}%`);
console.log(`Cost saved: $${stats.totalCostSaved}`);
```

**Expected Result:** 60%+ DeepSeek usage, 50% cost savings

---

## ðŸ’¡ ADVANCED USAGE

### **4. Implement Streaming Responses (15 minutes)**

**What:** 3x better perceived speed with real-time token streaming

**Frontend Implementation:**
```typescript
import { useEffect, useState } from 'react';

function AIChat() {
  const [response, setResponse] = useState('');
  const [isStreaming, setIsStreaming] = useState(false);

  const sendMessage = async (query: string) => {
    setResponse('');
    setIsStreaming(true);

    try {
      // Call streaming endpoint
      const res = await fetch(
        `https://kwhnrlzibgfedtxpkbgb.supabase.co/functions/v1/make-server-57781ad9/ai/streaming/stream`,
        {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${publicAnonKey}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: 'deepseek',
            prompt: query,
          }),
        }
      );

      const reader = res.body?.getReader();
      const decoder = new TextDecoder();

      while (true) {
        const { done, value } = await reader!.read();
        if (done) break;

        const chunk = decoder.decode(value);
        const lines = chunk.split('\n');

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = JSON.parse(line.slice(6));
            
            if (data.type === 'token') {
              setResponse(prev => prev + data.content);
            } else if (data.type === 'complete') {
              setIsStreaming(false);
            }
          }
        }
      }
    } catch (error) {
      console.error('Streaming error:', error);
      setIsStreaming(false);
    }
  };

  return (
    <div>
      <div className="response-area">
        {response}
        {isStreaming && <span className="typing-indicator">â–‹</span>}
      </div>
      <button onClick={() => sendMessage('Hello!')}>
        Send Message
      </button>
    </div>
  );
}
```

**Expected Result:** Progressive rendering, 3x faster perceived speed

---

### **5. Create A/B Test Experiment (10 minutes)**

**What:** Test different prompts to optimize accuracy

**Example:**
```typescript
// Create experiment
const response = await fetch(
  `https://kwhnrlzibgfedtxpkbgb.supabase.co/functions/v1/make-server-57781ad9/ai/ab-testing/experiments/create`,
  {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${publicAnonKey}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      name: 'Task Suggester Optimization',
      description: 'Test concise vs detailed prompts',
      skillName: 'task-suggester',
      variants: [
        {
          id: 'control',
          name: 'Control (Current)',
          systemPrompt: 'Suggest tasks based on user context...',
          model: 'mistral',
          weight: 50,
        },
        {
          id: 'concise',
          name: 'Concise Prompt',
          systemPrompt: 'Suggest tasks:',
          model: 'deepseek',
          weight: 50,
        },
      ],
      traffic: {
        strategy: 'equal',
        minSampleSize: 100,
      },
      successMetric: {
        type: 'user_rating',
        goal: 'maximize',
      },
      status: 'running',
      startDate: Date.now(),
      createdBy: 'admin',
    }),
  }
);

const { experimentId } = await response.json();
console.log(`Experiment created: ${experimentId}`);

// After collecting data, analyze results
const analysis = await fetch(
  `https://kwhnrlzibgfedtxpkbgb.supabase.co/functions/v1/make-server-57781ad9/ai/ab-testing/experiments/${experimentId}/analysis`,
  { headers: { 'Authorization': `Bearer ${publicAnonKey}` } }
);

const { winner, recommendations } = await analysis.json();
console.log(`Winner: ${winner.variantName}`);
console.log(`Improvement: ${winner.improvementPercent}%`);
```

**Expected Result:** 15-25% improvement over 3 months

---

### **6. Enable Predictive Pre-Fetching (20 minutes)**

**What:** Near-instant responses by predicting user actions

**Track User Actions:**
```typescript
// In your app, track significant user actions
const trackAction = async (action: string, context?: any) => {
  await fetch(
    `https://kwhnrlzibgfedtxpkbgb.supabase.co/functions/v1/make-server-57781ad9/ai/prefetch/track-action`,
    {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${publicAnonKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        userId: currentUser.id,
        timestamp: Date.now(),
        action,
        context,
      }),
    }
  );
};

// Track actions throughout your app
trackAction('view_schedule');
trackAction('create_task');
trackAction('check_energy');
```

**Check for Pre-Fetched Responses:**
```typescript
const sendQuery = async (query: string) => {
  // Check if response was pre-fetched
  const prefetchRes = await fetch(
    `https://kwhnrlzibgfedtxpkbgb.supabase.co/functions/v1/make-server-57781ad9/ai/prefetch/check-prefetch`,
    {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${publicAnonKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        userId: currentUser.id,
        query,
      }),
    }
  );

  const { hit, response } = await prefetchRes.json();

  if (hit) {
    // Instant delivery!
    console.log('Pre-fetched response (instant!)');
    return response;
  } else {
    // Normal AI call
    console.log('Calling AI model...');
    // ... normal flow
  }
};
```

**Expected Result:** Instant responses for predicted queries

---

## ðŸ“Š MONITORING & METRICS

### **Access the Observatory Dashboard:**

**Component Usage:**
```typescript
import { AIObservatoryDashboard } from './components/admin/AIObservatoryDashboard';

function AdminPage() {
  return (
    <div>
      <h1>AI Observatory</h1>
      <AIObservatoryDashboard />
    </div>
  );
}
```

**Key Metrics to Monitor:**

1. **Total Requests** - Volume trend
2. **Total Cost** - Budget tracking
3. **Cache Hit Rate** - Target: >60%
4. **DeepSeek Usage** - Target: >60%
5. **Average Latency** - Target: <500ms

**Set Up Alerts:**
Alerts are automatic! Check the dashboard for:
- Cost spikes
- High error rates
- Latency increases
- Model failures

---

## ðŸŽ¯ OPTIMIZATION WORKFLOW

### **Weekly Optimization Routine:**

**Monday:** Review Observatory Dashboard
- Check total costs
- Identify high-cost skills
- Review success rates

**Wednesday:** Analyze A/B Tests
- Check experiment progress
- Review sample sizes
- Update traffic allocation if needed

**Friday:** Cache Optimization
- Review top cached queries
- Clear stale cache if needed
- Adjust TTL settings

**Monthly:** Deep Dive
- Compare month-over-month costs
- Analyze router efficiency
- Review context optimization stats
- Update prediction models

---

## ðŸ’° COST TRACKING

### **Check Current Costs:**
```typescript
const response = await fetch(
  `https://kwhnrlzibgfedtxpkbgb.supabase.co/functions/v1/make-server-57781ad9/ai/observatory/cost-projection`,
  { headers: { 'Authorization': `Bearer ${publicAnonKey}` } }
);

const { projection } = await response.json();

console.log(`Daily: $${projection.daily}`);
console.log(`Monthly: $${projection.monthly}`);
console.log(`Yearly: $${projection.yearly}`);
console.log(`Cache savings (monthly): $${projection.monthlySavingsFromCache}`);
```

### **Cost Optimization Checklist:**
- [ ] Cache hit rate >60%
- [ ] DeepSeek usage >60%
- [ ] Context optimization enabled
- [ ] A/B tests running for high-volume skills
- [ ] Predictive pre-fetch enabled for power users

---

## ðŸ”§ TROUBLESHOOTING

### **Low Cache Hit Rate (<40%)**
**Cause:** Queries too varied  
**Fix:** 
- Lower similarity threshold (default: 0.85 â†’ 0.80)
- Increase TTL (default: 1 hour â†’ 2 hours)

```typescript
await fetch('/ai/cache/config', {
  method: 'POST',
  body: JSON.stringify({
    similarityThreshold: 0.80,
    defaultTTLMs: 7200000, // 2 hours
  }),
});
```

### **High Costs Despite Optimization**
**Cause:** Too much Mistral usage  
**Fix:** Review router stats, ensure structured tasks use DeepSeek

```typescript
// Check routing breakdown
const { stats } = await fetch('/ai/router/stats').then(r => r.json());
console.log(`DeepSeek: ${stats.deepseekPercentage}%`);

// If too low, check task classification
```

### **Slow Responses**
**Cause:** Not using streaming or cache  
**Fix:**
1. Implement streaming for all AI interactions
2. Ensure cache is enabled
3. Check prefetch hit rate

---

## ðŸ“š NEXT STEPS

1. **Week 1:** Monitor baseline metrics in Observatory Dashboard
2. **Week 2:** Implement streaming in 1-2 key features
3. **Week 3:** Create first A/B test for highest-volume skill
4. **Week 4:** Enable pre-fetching for common user flows
5. **Month 2:** Optimize based on real-world data

---

## ðŸŽ‰ SUCCESS INDICATORS

You're on the right track when you see:

âœ… Cache hit rate trending toward 60-80%  
âœ… DeepSeek usage at 60%+  
âœ… Average latency <500ms  
âœ… Monthly costs 70%+ below baseline  
âœ… User engagement with AI features increasing

---

## ðŸ“ž SUPPORT

**Dashboard:** https://syncscript.app/admin/ai-observatory  
**Documentation:** `/OPENCLAW_PHASE4_AI_ENHANCEMENTS_COMPLETE.md`  
**Master Guide:** `/SYNCSCRIPT_MASTER_GUIDE.md`

**All systems include detailed error logging** - check Supabase Edge Function logs for any issues.

---

**Phase 4 Status:** âœ… **DEPLOYED & READY**

Start with the Observatory Dashboard and work your way through the advanced features!
